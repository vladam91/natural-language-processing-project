{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import every library and package needed for project\n",
    "\n",
    "#import pandas lib for table data.\n",
    "import pandas as pd\n",
    "\n",
    "#Our bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#Our logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Our support vector machine model\n",
    "from sklearn import svm\n",
    "\n",
    "#Converts text words into numbers for model training.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#import regex lib\n",
    "import re\n",
    "\n",
    "\n",
    "annotatedData = pd.read_csv(\"data.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting only columns that matter for model training.\n",
    "corpus = annotatedData[['QueryText' , 'CommentText']]\n",
    "\n",
    "y = pd.DataFrame({'SimilarityScor' : annotatedData['SimilarityScor']})\n",
    "#y = annotatedData['SimilarityScor']\n",
    "\n",
    "query_vectorizer = CountVectorizer(ngram_range=(1,1)) # to use bigrams ngram_range=(2,2)\n",
    "query_vectors = query_vectorizer.fit_transform(annotatedData['QueryText'])\n",
    "\n",
    "comment_vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "comment_vectors = comment_vectorizer.fit_transform(annotatedData['CommentText'])\n",
    "\n",
    "comment_columns = comment_vectorizer.get_feature_names()\n",
    "query_columns = query_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#returns number of words in string.\n",
    "def countWords(s):\n",
    "    return len(re.findall(r'\\w+', s))\n",
    "\n",
    "#find common words in two strings.\n",
    "def findCommonWords(s1, s2):\n",
    "      s1 = s1.lower()\n",
    "      s2 = s2.lower()\n",
    "      s1List = s1.split(\" \")\n",
    "      s2List = s2.split(\" \")\n",
    "      return len(list(set(s1List)&set(s2List)))\n",
    "    \n",
    "\n",
    "#makes new dataframe which is then used to train our models.\n",
    "def processData(corpus, y) :\n",
    "    \n",
    "    allColumns = ['numWordsQuery','numWordsComment','numCommonWords','SimilarityScor']\n",
    "    \n",
    "    for name in comment_columns:\n",
    "        allColumns.append(name)      \n",
    "         \n",
    "    d = {}\n",
    "    \n",
    "    for column in allColumns:\n",
    "        d[column] = []\n",
    "        \n",
    "    for index,row in corpus.iterrows():\n",
    "        \n",
    "        d['numWordsQuery'].append(countWords(row['QueryText']))\n",
    "        d['numWordsComment'].append(countWords(row['CommentText']))\n",
    "        d['numCommonWords'].append(findCommonWords(row['QueryText'],row['CommentText']))\n",
    "        d['SimilarityScor'].append(y.iloc[index]['SimilarityScor'])\n",
    "        #d['NumericScore'].append(y.iloc[index]['NumericScore'])\n",
    "    \n",
    "        vectorComment = comment_vectorizer.transform([row['CommentText']])\n",
    "        vectorComment = vectorComment.toarray()\n",
    "    \n",
    "        #for i, commentCol in enumerate(allColumns[5:572]):\n",
    "        for i, commentCol in enumerate(allColumns[4:]):\n",
    "            d[commentCol].append(vectorComment[0][i])\n",
    "        \n",
    "    return pd.DataFrame.from_dict(d)\n",
    "    \n",
    "\n",
    "\n",
    "def processPredictionData(corpus) :\n",
    "    \n",
    "    allColumns = ['numWordsQuery','numWordsComment','numCommonWords']\n",
    "    \n",
    "    for name in comment_columns:\n",
    "        allColumns.append(name)        \n",
    "         \n",
    "    d = {}\n",
    "    \n",
    "    for column in allColumns:\n",
    "        d[column] = []\n",
    "        \n",
    "    for index,row in corpus.iterrows():\n",
    "        \n",
    "        d['numWordsQuery'].append(countWords(row['QueryText']))\n",
    "        d['numWordsComment'].append(countWords(row['CommentText']))\n",
    "        d['numCommonWords'].append(findCommonWords(row['QueryText'],row['CommentText']))\n",
    "\n",
    "        vectorComment = comment_vectorizer.transform([row['CommentText']])\n",
    "        vectorComment = vectorComment.toarray()\n",
    "        \n",
    "        vectorQuery = query_vectorizer.transform([row['QueryText']])\n",
    "        vectorQuery = vectorQuery.toarray()\n",
    "    \n",
    "        for i, commentCol in enumerate(allColumns[3:570]):\n",
    "            d[commentCol].append(vectorComment[0][i])\n",
    "     \n",
    "     \n",
    "    return pd.DataFrame.from_dict(d)\n",
    "                                 \n",
    "                                 \n",
    "                                 \n",
    "trainingData = processData(corpus,y)    \n",
    "\n",
    "y = trainingData['SimilarityScor']\n",
    "y = y.astype('int')\n",
    "\n",
    "#z = trainingData['NumericScore']\n",
    "#z = z.astype('int')\n",
    "\n",
    "#X = trainingData.drop(['NumericScore','SimilarityScor'], 1)\n",
    "X = trainingData.drop('SimilarityScor', 1)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57407407 0.66666667 0.53703704 0.51851852 0.62962963 0.66666667\n",
      " 0.62962963 0.55555556 0.59259259 0.62264151]\n",
      "Accuracy:  0.5993011879804333\n"
     ]
    }
   ],
   "source": [
    "#LOGISTICAL REGRESSION\n",
    "\n",
    "#10 layer cross validation to train and validate logistical regression model with tuning hyper params.\n",
    "logReg = LogisticRegression(penalty='l2',solver = 'liblinear', max_iter=150000)\n",
    "p_grid_lr = {'classifier__C' : [0.1, 0.5, 1.2]}\n",
    "p_logReg = Pipeline([('classifier', logReg)])\n",
    "gs_logReg = GridSearchCV(estimator=p_logReg, param_grid=p_grid_lr, cv = 10, scoring='accuracy')\n",
    "\n",
    "gs_logReg.fit(x_train,y_train)\n",
    "\n",
    "acc = cross_val_score(gs_logReg, x_train, y_train, cv = 10)\n",
    "\n",
    "print(acc)\n",
    "print(\"Accuracy: \", acc.mean())\n",
    "\n",
    "bestLRModel = gs_logReg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59259259 0.7037037  0.57407407 0.55555556 0.66666667 0.66666667\n",
      " 0.64814815 0.55555556 0.53703704 0.64150943]\n",
      "Accuracy:  0.6141509433962266\n"
     ]
    }
   ],
   "source": [
    "# 10 layer cross validation to train and validate SVM model.\n",
    "svmModel = svm.SVC(kernel='linear')\n",
    "#svmModel = svm.LinearSVC(penalty='l2', loss='squared_hinge', max_iter = 10000)\n",
    "\n",
    "p_grid_svm = {'classifier__C' : [0.3, 0.5, 0.9]}\n",
    "p_svm = Pipeline([('classifier', svmModel)])\n",
    "gs_SVM = GridSearchCV(estimator=p_svm, param_grid=p_grid_svm, cv = 10, scoring='accuracy')\n",
    "\n",
    "acc = cross_val_score(gs_SVM, x_train, y_train, cv = 10)\n",
    "\n",
    "print(acc)\n",
    "print(\"Accuracy: \", acc.mean())\n",
    "\n",
    "gs_SVM.fit(X,y)\n",
    "\n",
    "bestSVMModel = gs_SVM.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44117647 0.52941176 0.30882353 0.42647059 0.43283582 0.41791045\n",
      " 0.47761194 0.40298507 0.43283582 0.47761194]\n",
      "Accuracy:  0.4347673397717296\n"
     ]
    }
   ],
   "source": [
    "#NAIVE BAYES \n",
    "\n",
    "#bayes model with 10 layer cross validation\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "params = {}\n",
    "nb = MultinomialNB()\n",
    "gs = GridSearchCV(nb, cv=skf, param_grid=params, return_train_score=True)\n",
    "\n",
    "p_bayes = Pipeline([('classifier', nb)])\n",
    "acc = cross_val_score(p_bayes, X, y, cv = 10);\n",
    "\n",
    "print(acc)\n",
    "print(\"Accuracy: \", acc.mean())\n",
    "\n",
    "gs.fit(X,y)\n",
    "\n",
    "bestSVMModel = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-eb97e55b560d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtestSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'QueryText'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'CommentText'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtestData\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mprocessPredictionData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpredictedData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbestLRModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-c8201d9736e8>\u001b[0m in \u001b[0;36mprocessPredictionData\u001b[1;34m(corpus)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[1;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[0;32m   1307\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"only recognize index or columns for orient\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1309\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m     def to_numpy(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         ]\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "#Predictions\n",
    "\n",
    "testSet = pd.read_csv(\"predict.txt\", sep='\\t')\n",
    "\n",
    "testSet = testSet[['QueryText' , 'CommentText']]\n",
    "\n",
    "testData =  processPredictionData(testSet)\n",
    "\n",
    "predictedData = bestLRModel.predict(testData)\n",
    "predictedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.10700631, 1.27678253, 2.29788204])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear regression\n",
    "\n",
    "linReg = LinearRegression()\n",
    "\n",
    "#params = linReg.get_params().keys()\n",
    "#params\n",
    "\n",
    "#p_grid_lr = {'alpha' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "#p_linReg = Pipeline([('classifier', linReg)])\n",
    "#gs_linReg = GridSearchCV(estimator=p_linReg, param_grid=p_grid_lr, cv = 10, scoring='accuracy')\n",
    "\n",
    "#gs_linReg.fit(X,y)\n",
    "\n",
    "#acc = cross_val_score(gs_linReg, X, y, cv = 10)\n",
    "\n",
    "#print(acc)\n",
    "#print(\"Accuracy: \", acc.mean())\n",
    "\n",
    "#bestLRModel = gs_logReg.best_estimator_\n",
    "\n",
    "linReg.fit(X, y)\n",
    "\n",
    "testSet = pd.read_csv(\"predict.txt\", sep='\\t')\n",
    "\n",
    "testSet = testSet[['QueryText' , 'CommentText']]\n",
    "\n",
    "testData =  processPredictData(testSet)\n",
    "\n",
    "#testData.head()\n",
    "\n",
    "\n",
    "#t = testSet[]\n",
    "\n",
    "#X.head()\n",
    "\n",
    "#\n",
    "\n",
    "#testData\n",
    "\n",
    "#predictedData = linReg.predict(testData)\n",
    "#predictedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
